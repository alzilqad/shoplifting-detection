{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "We are mainly using openCV, keras, tensorflow libraries for this research. The purpose of this research is to find out the best performing model than can classify shoplifiting from videos and provide alert signals to the shop incharges to prevent this outlaw. We are going to try our best to find the best model and parameter that will show case the best performance.  \n",
    "\n",
    "### The models that we will try out are\n",
    "- VGG16 (224 x 224 x 3)\n",
    "- VGG19 (224 x 224 x 3)\n",
    "- ResNet50 (224 x 224 x 3)\n",
    "- DenseNet121 (224 x 224 x 3)\n",
    "- InceptionV3 (299 x 299 x 3)\n",
    "\n",
    "The first task is to import the libraries - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle as p\n",
    "import imutils\n",
    "\n",
    "from scipy import ndimage\n",
    "from moviepy.editor import *\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.applications import ResNet50, VGG16, VGG19, DenseNet121\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, ZeroPadding2D, BatchNormalization, Activation, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputmodelpath = r'model/'\n",
    "outputbinarizerpath = r'model/'\n",
    "\n",
    "DATA_DIR = './data'\n",
    "CATEGORIES = ['Shoplifting', 'Normal_Activity']\n",
    "data = []\n",
    "labels = []\n",
    "global train_x, test_x, train_y, test_y, train_gen, validation_gen, lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are declaring some paths to save our **model** and **binarizer**. Now, we will start our preprocessing. The first step is to load the **images correctly**.\n",
    "\n",
    "\n",
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_to_images():\n",
    "    pathOut = \"./sample\"\n",
    "    count = 0\n",
    "    counter = 1\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for c in CATEGORIES:\n",
    "        path = os.path.join(DATA_DIR, c)\n",
    "        class_num = CATEGORIES.index(c)\n",
    "\n",
    "        for vid in tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                vid = os.path.join(path, vid)\n",
    "                cap = cv2.VideoCapture(vid)\n",
    "                count = 0\n",
    "                counter += 1\n",
    "                success = True\n",
    "                while success:\n",
    "                    success,image = cap.read()\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "            #         print('read a new frame:',success)\n",
    "                    if count%30 == 0 :\n",
    "                        frames.append([image, class_num])\n",
    "                        cv2.imwrite(pathOut + 'frame%d.jpg'%count,image)\n",
    "                    count+=1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    print(count, \" frames extracted\")\n",
    "    # frames = np.array(frames)\n",
    "    # print(\"data shape =\\t\", frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(IMG_SIZE = 224):\n",
    "    for c in CATEGORIES:\n",
    "        path = os.path.join(DATA_DIR, c)\n",
    "        class_num = CATEGORIES.index(c)\n",
    "\n",
    "        for img in  tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_COLOR)\n",
    "                img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "                img_resized = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                data.append([img_resized, class_num])\n",
    "                labels.append(CATEGORIES[class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Images loaded successfully!\")\n",
    "    print(f\"Found {len(data)} images and {len(labels)} labels from {len(CATEGORIES)} Categories\")\n",
    "    #data = np.array(data)\n",
    "#     np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the images for visual assessment of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_data():\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(data[i][0])\n",
    "        plt.xlabel(CATEGORIES[data[i][1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data into train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    global lb\n",
    "    \n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        x.append(data[i][0])\n",
    "        y.append(data[i][1])\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    y = lb.fit_transform(y)\n",
    "    \n",
    "    global train_x, test_x, train_y, test_y\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, stratify = y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting the data for better training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data():\n",
    "    global train_gen, validation_gen\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  rotation_range=40,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "    train_gen = train_datagen.flow(train_x, train_y, batch_size=32)\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "    validation_gen = validation_datagen.flow(test_x, test_y)\n",
    "    \n",
    "\n",
    "def augment_data_resnet():\n",
    "    global train_gen, validation_gen\n",
    "\n",
    "    train_datagen = ImageDataGenerator(dtype='float32',preprocessing_function=preprocess_input)\n",
    "    validation_datagen = ImageDataGenerator(dtype='float32',preprocessing_function=preprocess_input)\n",
    "    \n",
    "    train_gen = train_datagen.flow(train_x, train_y, batch_size=32)\n",
    "    validation_gen = validation_datagen.flow(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_vgg16():\n",
    "    baseModel = VGG16(weights=\"imagenet\", include_top = False, input_tensor = Input(shape=(224,224,3)))\n",
    "    \n",
    "    headModel = baseModel.output\n",
    "    headModel = MaxPooling2D(pool_size=(7,7))(headModel)\n",
    "    headModel = Flatten(name=\"Flatten\")(headModel)\n",
    "    headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    \n",
    "    for basemodellayers in baseModel.layers:\n",
    "        basemodellayers.trainable = False\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_vgg19():\n",
    "    baseModel = VGG19(weights=\"imagenet\", include_top = False, input_tensor = Input(shape=(224,224,3)))\n",
    "    headModel = baseModel.output\n",
    "    headModel = MaxPooling2D(pool_size=(7,7))(headModel)\n",
    "    headModel = Flatten(name=\"Flatten\")(headModel)\n",
    "    headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    \n",
    "    for basemodellayers in baseModel.layers:\n",
    "        basemodellayers.trainable = False\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_resnet50():\n",
    "    baseModel = ResNet50(weights=\"imagenet\", include_top = False, input_tensor = Input(shape=(224,224,3)))\n",
    "    \n",
    "    headModel = baseModel.output\n",
    "    headModel = MaxPooling2D(pool_size=(7,7))(headModel)\n",
    "    headModel = Flatten(name=\"Flatten\")(headModel)\n",
    "    headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    \n",
    "    for basemodellayers in baseModel.layers:\n",
    "        basemodellayers.trainable = False\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_densenet121():\n",
    "    baseModel = DenseNet121(weights=\"imagenet\", include_top = False, input_tensor = Input(shape=(224,224,3)))\n",
    "    headModel = baseModel.output\n",
    "    headModel = MaxPooling2D(pool_size=(7,7))(headModel)\n",
    "    headModel = Flatten(name=\"Flatten\")(headModel)\n",
    "    headModel = Dense(100, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.2)(headModel)\n",
    "    headModel = Dense(20, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.2)(headModel)\n",
    "    headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    \n",
    "    for basemodellayers in baseModel.layers:\n",
    "        basemodellayers.trainable = False\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inceptionV3():\n",
    "    baseModel = InceptionV3(weights='imagenet', include_top=False, input_tensor=Input(shape=(299,299,3)), pooling='avg')\n",
    "    \n",
    "    headModel = baseModel.output\n",
    "#     headModel = MaxPooling2D(pool_size=(11,11))(headModel)\n",
    "#     headModel = Flatten(name=\"Flatten\")(headModel)\n",
    "    headModel = Dense(1000, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.6)(headModel)\n",
    "    headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    \n",
    "#     headModel = Dense(1000, activation=\"relu\")(headModel)\n",
    "#     headModel = Dropout(0.2)(headModel)\n",
    "#     headModel = Dense(200, activation=\"relu\")(headModel)\n",
    "#     headModel = Dropout(0.2)(headModel)\n",
    "#     headModel = Dense(40, activation=\"relu\")(headModel)\n",
    "#     headModel = Dropout(0.2)(headModel)\n",
    "#     headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
    "#     model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    \n",
    "    for basemodellayers in baseModel.layers:\n",
    "        basemodellayers.trainable = False\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_custom():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(100, (3, 3), padding='same', activation='relu', input_shape=(224,224,3)))\n",
    "    model.add(Conv2D(100, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(50, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(50, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(25, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(25, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epch = 20, opt = SGD(learning_rate=0.01), ls = \"binary_crossentropy\"):\n",
    "    \n",
    "    model.compile(loss=ls, optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    history = model.fit_generator(\n",
    "        train_gen,\n",
    "        steps_per_epoch = len(train_x) // 32,\n",
    "        validation_data = validation_gen,\n",
    "        validation_steps = len(test_x)//32,\n",
    "        epochs = epch\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    score = model.evaluate(test_x, test_y, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Model and the Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    model.save(outputmodelpath)\n",
    "    lbinarizer = open(outputbinarizerpath)\n",
    "    lbinarizer.write(p.dump(lb))\n",
    "    lbinarizer.close()\n",
    "\n",
    "\n",
    "def save_history_as_pickle(history):\n",
    "    with open('/trainHistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "\n",
    "def save_history_as_json(history):\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    \n",
    "    hist_json_file = 'history/model.json' \n",
    "    with open(hist_json_file, mode='w') as f:\n",
    "        hist_df.to_json(f)\n",
    "\n",
    "\n",
    "def save_history_as_json(history):\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    \n",
    "    hist_csv_file = 'history/model.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(history, epoch):\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    xc = range(epoch)\n",
    "\n",
    "    plt.figure(1,figsize=(7,5))\n",
    "    plt.plot(xc,train_loss)\n",
    "    plt.plot(xc,val_loss)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('train_loss vs val_loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['train','val'])\n",
    "    #print(plt.style.available) # use bmh, classic,ggplot for big pictures\n",
    "    plt.style.use(['classic'])\n",
    "\n",
    "    plt.figure(2,figsize=(7,5))\n",
    "    plt.plot(xc,train_acc)\n",
    "    plt.plot(xc,val_acc)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('train_acc vs val_acc')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['train','val'],loc=4)\n",
    "    #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "    plt.style.use(['classic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████▎                              | 544/890 [00:08<00:01, 181.04it/s]"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "preprocess_data(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_vgg16() #sgd, binary_crossentropy\n",
    "# model = model_vgg19() #sgd, binary_crossentropy\n",
    "augment_data_resnet()\n",
    "model = model_resnet50()\n",
    "# model = model_densenet121() #adam, categorical_crossentropy\n",
    "# model = model_inceptionV3() #rms, hinge / 65% adam1, hinge, relu->dropout .75->sigmoid\n",
    "# model = model_custom()\n",
    "plot_model(model, to_file='model_plot.png')\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "opt_adam1= Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.999, epsilon=0.1, amsgrad=False)\n",
    "opt_sgd  = SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
    "opt_sgd1 = SGD(learning_rate=0.01, momentum=0.0, nesterov=True)\n",
    "opt_rms  = RMSprop(learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=0.1, centered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = train_model(model, 20, opt_rms, \"hinge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(history, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(outputmodelpath+\"resnet50/\")\n",
    "\n",
    "lbinarizer = open(r\"E:\\Project\\Python\\Jupyter\\Thesis\\Fully Working\\model\\resnet50\\binarizer.pkl\", \"wb\")\n",
    "p.dump(lb, lbinarizer)\n",
    "lbinarizer.close()\n",
    "                  \n",
    "# with open('/trainHistoryDict', 'wb') as file_pi:\n",
    "#         p.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.callbacks.History object at 0x000001EFA45415C0>\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbinarizer = open(r\"E:\\Project\\Python\\Jupyter\\Thesis\\Fully Working\\model\\binarizer.pkl\", \"wb\")\n",
    "p.dump(lb, lbinarizer)\n",
    "lbinarizer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
