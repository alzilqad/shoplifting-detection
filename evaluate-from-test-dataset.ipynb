{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "DATA_DIR = './data/test/'\n",
    "CATEGORIES = ['Shoplifting', 'Normal_Activity']\n",
    "outputmodelpath = r'model/VGG16/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_to_images(IMG_SIZE = 224):\n",
    "    count = 0\n",
    "    counter = 1\n",
    "    frames = []\n",
    "\n",
    "    for c in CATEGORIES:\n",
    "        path = os.path.join(DATA_DIR, c)\n",
    "        class_num = CATEGORIES.index(c)\n",
    "\n",
    "        for vid in tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                vid = os.path.join(path, vid)\n",
    "                cap = cv2.VideoCapture(vid)\n",
    "                count = 0\n",
    "                counter += 1\n",
    "                success = True\n",
    "                while success:\n",
    "                    success,image = cap.read()\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    #                 print('read a new frame:',success)\n",
    "                    if count%30 == 0 :\n",
    "                        frames.append([image, class_num])\n",
    "                        cv2.imwrite(DATA_DIR + c +'/frame%d.jpg'%count,image)\n",
    "                    count+=1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    print(count, \" frames extracted\")\n",
    "    # frames = np.array(frames)\n",
    "    # print(\"data shape =\\t\", frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(IMG_SIZE = 224, data=[], labels=[]):\n",
    "    for c in CATEGORIES:\n",
    "        path = os.path.join(DATA_DIR, c)\n",
    "        class_num = CATEGORIES.index(c)\n",
    "\n",
    "        for img in  tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_COLOR)\n",
    "                img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "                img_resized = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                data.append([img_resized, class_num])\n",
    "                labels.append(CATEGORIES[class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Images loaded successfully!\")\n",
    "    print(f\"Found {len(data)} images and {len(labels)} labels from {len(CATEGORIES)} Categories\")\n",
    "    #data = np.array(data)\n",
    "    #np.random.shuffle(data)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 670.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 61/61 [00:00<00:00, 728.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Images loaded successfully!\n",
      "Found 196 images and 196 labels from 2 Categories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data, labels = preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [datum[0] for datum in data]\n",
    "y = [datum[1] for datum in data]\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(outputmodelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X, y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
